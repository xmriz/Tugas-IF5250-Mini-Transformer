{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e27dd9",
   "metadata": {},
   "source": [
    "# **Mini Transformer for Dialogue Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37645314",
   "metadata": {},
   "source": [
    "## **1. Import Library & Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ffdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af9e52",
   "metadata": {},
   "source": [
    "## **2. Import Library & Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad193e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DailyDialog\n",
    "raw = load_dataset('li2017dailydialog/daily_dialog')  # train/validation/test \n",
    "\n",
    "def preprocess(example):\n",
    "    toks = ['<bos>']\n",
    "    for utt in example['dialog']:\n",
    "        toks += utt.split() + ['<sep>']\n",
    "    toks[-1] = '<eos>'\n",
    "    return {'tokens': toks}\n",
    "\n",
    "train_raw = raw['train'].map(preprocess).select(range(5000))\n",
    "val_raw   = raw['validation'].map(preprocess).select(range(1000))\n",
    "print(f\"Train: {len(train_raw)}, Val: {len(val_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e6c14",
   "metadata": {},
   "source": [
    "## **3. PyTorch Dataset & DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(Dataset):\n",
    "    def __init__(self, data, toi, max_len=64):\n",
    "        self.data, self.toi, self.max_len = data, toi, max_len\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "\n",
    "    def encode(self, toks):\n",
    "        ids = [self.toi.get(t, self.toi['<unk>']) for t in toks]\n",
    "        if len(ids)>self.max_len: ids=ids[:self.max_len]\n",
    "        else: ids += [self.toi['<pad>']]*(self.max_len-len(ids))\n",
    "        return ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = self.encode(self.data[idx]['tokens'])\n",
    "        x = torch.tensor(ids[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(ids[1:],  dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_ds = DialogDataset(train_raw, toi)\n",
    "val_ds   = DialogDataset(val_raw,   toi)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95b62c",
   "metadata": {},
   "source": [
    "## **4. Positional Encoding Varian**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8f4a0",
   "metadata": {},
   "source": [
    "### 4.1 Sinusoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPE(nn.Module):\n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super().__init__()\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        i   = torch.arange(d_model//2).unsqueeze(0)\n",
    "        angles = pos / (10000**(2*i/d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:,0::2], pe[:,1::2] = torch.sin(angles), torch.cos(angles)\n",
    "        self.pe = pe.unsqueeze(0).to(device)\n",
    "\n",
    "    def forward(self, x): return x + self.pe[:,:x.size(1),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608491c",
   "metadata": {},
   "source": [
    "### 4.1 Learnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f729d3",
   "metadata": {},
   "source": [
    "class LearnablePE(nn.Module):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(max_len, d_model)\n",
    "    def forward(self, x):\n",
    "        pos = torch.arange(x.size(1), device=x.device).unsqueeze(0)\n",
    "        return self.embed(pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdddcc6",
   "metadata": {},
   "source": [
    "## **5. Arsitektur Decoder-Only Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1  = nn.LayerNorm(d_model)\n",
    "        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.ln2  = nn.LayerNorm(d_model)\n",
    "        self.ff   = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff), nn.GELU(),\n",
    "            nn.Linear(d_ff, d_model), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (T, B, D)\n",
    "        T,B,_ = x.size()\n",
    "        mask  = torch.triu(torch.full((T,T), float('-inf'), device=x.device), 1)\n",
    "        res = x\n",
    "        x = self.ln1(x)\n",
    "        x,_ = self.attn(x, x, x, attn_mask=mask)\n",
    "        x = res + x\n",
    "        res = x\n",
    "        x = self.ln2(x)\n",
    "        x = res + self.ff(x)\n",
    "        return x\n",
    "\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        d, V, L = cfg['d_model'], cfg['vocab_size'], cfg['max_len']\n",
    "        self.tok_embed = nn.Embedding(V, d)\n",
    "        self.pos_embed = (SinusoidalPE(d,L) \n",
    "                          if cfg['pos']=='sinusoidal' \n",
    "                          else LearnablePE(L,d))\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d, cfg['nhead'], cfg['d_ff']) \n",
    "            for _ in range(cfg['nlayers'])\n",
    "        ])\n",
    "        self.ln_f = nn.LayerNorm(d)\n",
    "        self.head = nn.Linear(d, V, bias=False)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        B,T = input_ids.shape\n",
    "        x = self.tok_embed(input_ids) * math.sqrt(self.tok_embed.embedding_dim)\n",
    "        if isinstance(self.pos_embed, SinusoidalPE):\n",
    "            x = self.pos_embed(x)\n",
    "        else:\n",
    "            x = x + self.pos_embed(input_ids)\n",
    "        x = x.transpose(0,1)  # (T,B,D)\n",
    "        for layer in self.layers: x = layer(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x) # (T,B,V)\n",
    "        return logits.transpose(0,1)  # (B,T,V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5a4be",
   "metadata": {},
   "source": [
    "## **6. Training & Evaluasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5223460",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "  'd_model':64, 'nhead':1, 'd_ff':256,\n",
    "  'nlayers':2, 'vocab_size':len(itos), 'max_len':64,\n",
    "  'pos':'sinusoidal'\n",
    "}\n",
    "model = DecoderOnlyTransformer(cfg).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=toi['<pad>'])\n",
    "\n",
    "def train_epoch():\n",
    "    model.train(); total=0\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1,logits.size(-1)), y.view(-1))\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total/len(train_loader)\n",
    "\n",
    "def eval_epoch(loader):\n",
    "    model.eval(); total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            total += criterion(logits.view(-1,logits.size(-1)), y.view(-1)).item()\n",
    "    return total/len(loader)\n",
    "\n",
    "# Loop Pelatihan\n",
    "for exp in ['exp1','exp2','exp3']:\n",
    "    print(\"===\",exp,\"===\")\n",
    "    for epoch in range(3):\n",
    "        tr = train_epoch()\n",
    "        vl = eval_epoch(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: train_loss={tr:.4f}, val_loss={vl:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50a16e",
   "metadata": {},
   "source": [
    "## **7. Inference: Greedy Decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_generate(max_len=64):\n",
    "    model.eval()\n",
    "    ids = torch.full((1,1), toi['<bos>'], dtype=torch.long, device=device)\n",
    "    for _ in range(max_len-1):\n",
    "        logits = model(ids)               # (1,T,V)\n",
    "        next_id = logits[:,-1].argmax(-1) # (1,)\n",
    "        ids = torch.cat([ids, next_id.unsqueeze(-1)], dim=1)\n",
    "        if next_id.item()==toi['<eos>']: break\n",
    "    return [itos[i] for i in ids.squeeze().tolist()]\n",
    "\n",
    "print(\"Generated:\", greedy_generate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7be8d",
   "metadata": {},
   "source": [
    "## **8. Evaluasi dengan Hugging Face Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrik\n",
    "rouge  = evaluate.load('rouge')    # ROUGE-1/2/L\n",
    "bleu   = evaluate.load('bleu')     # BLEU\n",
    "meteor = evaluate.load('meteor')   # METEOR\n",
    "\n",
    "# Kumpulkan prediksi & referensi\n",
    "preds, refs = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x,y in val_loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        pred_ids = logits.argmax(-1).cpu().tolist()\n",
    "        for pi, yi in zip(pred_ids, y.tolist()):\n",
    "            # decode hingga eos\n",
    "            p = [itos[id] for id in pi if id not in [toi['<pad>']]]\n",
    "            r = [itos[id] for id in yi if id not in [toi['<pad>']]]\n",
    "            preds.append(\" \".join(p).split(\"<eos>\")[0].strip())\n",
    "            refs.append([\" \".join(r).split(\"<eos>\")[0].strip()])\n",
    "\n",
    "# Compute skor\n",
    "res_rouge  = rouge.compute(predictions=preds, references=refs)\n",
    "res_bleu   = bleu.compute(predictions=preds, references=refs)\n",
    "res_meteor = meteor.compute(predictions=preds, references=refs)\n",
    "\n",
    "print(\"ROUGE:\",  res_rouge)\n",
    "print(\"BLEU:\",   res_bleu)\n",
    "print(\"METEOR:\", res_meteor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubes-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
